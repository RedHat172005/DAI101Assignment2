{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ffb27b4-4c56-4540-af18-81ce1f00b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "703b8762-2944-4b70-9280-3ae4714ee984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.utils.class_weight import compute_class_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b343a868-17a2-4ab8-9828-a1a46286d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/VANISHA CHOUDHARY/Downloads/weatherAUS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2868d8c6-a227-46c6-819d-e676cef0c269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c32ff9d-9e3b-45b4-a0f9-276aeb9eccc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10e48b5f-61d0-4e4e-8880-e02f249b1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Date'])\n",
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adf7afff-09c6-4fa0-8b8e-9313ad460ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Class Distribution: Counter({0: 35194, 1: 9942})\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "for col in ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Split features and target variable\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Initial Class Distribution:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ef1bb37-c6e4-466b-a1eb-95307c68c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for evaluating model performance\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, class_weights=None):\n",
    "    model = RandomForestClassifier(class_weight=class_weights, random_state=40)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "    return accuracy, f1, auc\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {'Technique': [], 'Accuracy': [], 'F1 Score': [], 'AUC': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5ec044a-c179-446c-9e98-bb377d0b3542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Random Undersampling...\n",
      "After Undersampling: Counter({0: 9942, 1: 9942})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      8799\n",
      "           1       0.54      0.81      0.65      2485\n",
      "\n",
      "    accuracy                           0.81     11284\n",
      "   macro avg       0.74      0.81      0.76     11284\n",
      "weighted avg       0.85      0.81      0.82     11284\n",
      "\n",
      "Accuracy: 0.8066, F1 Score: 0.6487, AUC: 0.8925\n"
     ]
    }
   ],
   "source": [
    "# Doing Random Undersampling\n",
    "print(\"\\nApplying Random Undersampling...\")\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "print(\"After Undersampling:\", Counter(y_rus))\n",
    "accuracy, f1, auc = evaluate_model(X_rus, y_rus, X_test, y_test)\n",
    "results['Technique'].append('Random Undersampling')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['F1 Score'].append(f1)\n",
    "results['AUC'].append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd6fe7-2b4a-4d93-894a-d859e488f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Random Oversampling...\n",
      "After Oversampling: Counter({0: 35194, 1: 35194})\n"
     ]
    }
   ],
   "source": [
    "# Doing Random Oversampling\n",
    "print(\"\\nApplying Random Oversampling...\")\n",
    "ros = RandomOverSampler(random_state=40)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "print(\"After Oversampling:\", Counter(y_ros))\n",
    "accuracy, f1, auc = evaluate_model(X_ros, y_ros, X_test, y_test)\n",
    "results['Technique'].append('Random Oversampling')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['F1 Score'].append(f1)\n",
    "results['AUC'].append(auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21f6ada7-ec77-4b8f-a886-3ac58ec2e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE...\n",
      "After SMOTE: Counter({0: 35194, 1: 35194})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      8799\n",
      "           1       0.66      0.66      0.66      2485\n",
      "\n",
      "    accuracy                           0.85     11284\n",
      "   macro avg       0.78      0.78      0.78     11284\n",
      "weighted avg       0.85      0.85      0.85     11284\n",
      "\n",
      "Accuracy: 0.8503, F1 Score: 0.6589, AUC: 0.8939\n"
     ]
    }
   ],
   "source": [
    "#  SMOTE  (Synthetic Minority Oversampling Technique)\n",
    "print(\"\\nApplying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", Counter(y_smote))\n",
    "accuracy, f1, auc = evaluate_model(X_smote, y_smote, X_test, y_test)\n",
    "results['Technique'].append('SMOTE')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['F1 Score'].append(f1)\n",
    "results['AUC'].append(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "099aa311-13b1-4844-93e9-ac916b4e21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Tomek Links...\n",
      "After Tomek Links: Counter({0: 33538, 1: 9942})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      8799\n",
      "           1       0.74      0.57      0.64      2485\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.81      0.76      0.78     11284\n",
      "weighted avg       0.85      0.86      0.85     11284\n",
      "\n",
      "Accuracy: 0.8612, F1 Score: 0.6431, AUC: 0.8948\n"
     ]
    }
   ],
   "source": [
    "# Tomek Links\n",
    "print(\"\\nApplying Tomek Links...\")\n",
    "tl = TomekLinks()\n",
    "X_tl, y_tl = tl.fit_resample(X_train, y_train)\n",
    "print(\"After Tomek Links:\", Counter(y_tl))\n",
    "accuracy, f1, auc = evaluate_model(X_tl, y_tl, X_test, y_test)\n",
    "results['Technique'].append('Tomek Links')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['F1 Score'].append(f1)\n",
    "results['AUC'].append(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "960d3ecc-da79-42e5-97b1-826de3218c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Class Weighting...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      8799\n",
      "           1       0.78      0.50      0.61      2485\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.83      0.73      0.76     11284\n",
      "weighted avg       0.85      0.86      0.85     11284\n",
      "\n",
      "Accuracy: 0.8596, F1 Score: 0.6108, AUC: 0.8952\n",
      "\n",
      "Performance Metrics for Different Resampling Techniques:\n",
      "              Technique  Accuracy  F1 Score       AUC\n",
      "0  Random Undersampling  0.806629  0.648744  0.892489\n",
      "1   Random Oversampling  0.859713  0.653989  0.896746\n",
      "2                 SMOTE  0.850319  0.658857  0.893938\n",
      "3           Tomek Links  0.861219  0.643118  0.894781\n",
      "4       Class Weighting  0.859624  0.610811  0.895162\n"
     ]
    }
   ],
   "source": [
    "# Class Weighting\n",
    "print(\"\\nApplying Class Weighting...\")\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "accuracy, f1, auc = evaluate_model(X_train, y_train, X_test, y_test, class_weights=class_weights_dict)\n",
    "results['Technique'].append('Class Weighting')\n",
    "results['Accuracy'].append(accuracy)\n",
    "results['F1 Score'].append(f1)\n",
    "results['AUC'].append(auc)\n",
    "\n",
    "# Display final results in a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nPerformance Metrics for Different Resampling Techniques:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f257487-c786-49db-b645-b039af2a70bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
